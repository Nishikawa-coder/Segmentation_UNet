# Segmentation with Unet

Unet で画像のセグメンテーションを学習する。

## 目的

本実験では白黒画像内にある`butu`のピクセル単位での検出を Unet で学習することを目的としている。

## 原理

U-Net はセマンティックセグメンテーション用のモデルで、エンコーダとデコーダから成る U 字型のモデルである。  
エンコーダでは入力された画像を何度か畳み込み、その画像の特徴を抽出する。一方、デコーダではエンコーダによって抽出された特徴を受け取り、逆畳み込みによって、入力画像と同じサイズの確率マップを出力する。

## 実験の方法

本実験では、白黒画像とアノテーションマスク（`butu`の位置情報）がセットになっている x3 というデータセットを用い、U-Net を用いて学習し、画像中の`butu`の検出を行った。  
また、学習したモデルに対して推論を行い、PR 曲線および Average Precision、処理時間により評価を行った。

### 準備

ファイルを下記のように置いてください。

```
[user_name]
│
├── data
│   └── x3
└── class3(ディレクトリ名（何でも良い）)
    ├── dataset.py
    ├── train_inference.ipynb
    ├── unet_model.py
    ├── unet_parts.py
    ├── ・・・
    └──
```

[注] 接続しているマシンの`localtmp/users`に`rin(user_name)`を作成してください。

**train_inference.ipynb の全てのセルを再生させる事で学習時と推論時の動作を確認できます**。初期状態では、`train_model()`がコメントアウトされています。    
`show_detection()`では推論結果の画像と（緑：正しい推論、赤:間違った推論、青:推論されなかった gt）、推論の処理時間が表示されます。また、最後にPR曲線とaverage_precisionの曲線とそれぞれのaucが表示されます。

### 実験条件

データセット：x3("butu"のみがある画像 101 枚を使用。訓練：80 枚、検証：10 枚、テスト：11 枚)  
クラス：{0:背景 1:butu}    
最適化関数：Momentum SGD  
損失関数：交差エントロピー

#### (1) log_output_init_weight_1000_1000.csv

白黒データセットをRGBの型に変換。  
エポック数：1000  
学習率：1e-3  
損失関数の重み：loss_weight=(1,100)  
マシン：palkia 1  
バッチサイズ：4（batch_multiplier=6 なので実質24)  
color_mean = (0.485, 0.456, 0.406)  
color_std = (0.229, 0.224, 0.225)

#### (2) log_output_v1.csv

白黒データセットをグレースケールとして実験。  
エポック数：1000  
学習率：1e-3  
損失関数の重み：loss_weight=(1,70)  
マシン：palkia 1  
バッチサイズ：4（batch_multiplier=6 なので実質24)  
color_mean=0.18228737997050898  
color_std=0.15940997135888293  

#### (3) log_output_v4.csv

白黒データセットをグレースケールとして実験。また、データのスプリットの仕方をランダムにした。  
エポック数：300  
学習率：1e-2  
損失関数の重み：loss_weight=(1,100)  
マシン：palkia 0  
バッチサイズ：6（batch_multiplier=4 なので実質24)  
color_mean=0.18228737997050898  
color_std=0.15940997135888293

## 結果

### 白黒画像をRGBの型に変換してから学習

この時、データローダーに使うcolor_meanやcolor_stdの値は書籍にある物と同じ値を設定した。ロスのログは`log_output_init_weight_1000_1000.csv`にある。  

#### (1) 処理時間  
U-Netに画像を入力してoutputを出力するまでの時間をテストデータ11枚分測り合計した。  

time: `15.18376612663269` sec  

#### (2) PR曲線  

<p align="center"><img src="https://user-images.githubusercontent.com/77057905/178912220-8d2debc4-bac5-4d64-b0fc-93360aec5f13.png" width="45%">
<img src="https://user-images.githubusercontent.com/77057905/178914487-3d0c1c43-d941-48b2-b22b-c643ca5e41b6.png" width="45%"></p>
<p align="center">図1 RGBに変換した時のPR曲線</p>
図1に示すようなPR曲線となり、average_precisionが0.2615555615041095と、低い値となった。  

#### (3) 考えたこと  
右肩下がりの通常のPR曲線と比べて、図1は奇妙な形になってしまった(特にrecall=0ではprecisionが0になったり1になったりしていて振り幅が大きい)。この結果を踏まえて、2点問題点があると考えた。  

1点目は、白黒画像を無理やりRGBの型に変換したことである。グレースケールと比べて空間計算量が多くなるので、学習結果に影響がでるのではないかと考えた。    
2点目は、データセットをランダムにスプリットしたのではなく、for文を回して順番にスプリットしたことである。x3データセットは同じような画像が連続しているので、順番通りにスプリットすると、学習の幅が減ると考えた。  
これらを改善して以下のように実験をし直した。

### 白黒画像をグレースケールのまま学習

この時、データローダーに使うcolor_meanやcolor_stdの値は今回データセットとして扱う101枚のデータセットから一枚一枚の平均と標準偏差を計算し、それぞれの平均をcolor_mean、color_stdの値としている。ロスのログは`log_output_v1.csv`にある。

#### (1) 処理時間  
同様に処理時間を計算した。  

time: `14.51577353477478` sec

#### (2) PR曲線  

<p align="center"><img src="https://user-images.githubusercontent.com/77057905/178956841-65979129-a2c4-4180-8029-20905404235d.png" width="45%">
<img src="https://user-images.githubusercontent.com/77057905/178956941-6a751f91-f660-4d32-b481-fd9e6bbbd23a.png" width="45%"></p>
<p align="center">図2 グレースケールのままのPR曲線</p>
図2に示すようなPR曲線となり、average_precisionが0.20575667373625753となった。  
RGBに変換した時と比較して、右肩下がりのPR曲線にはなった。しかし、average_precisionが下がってしまった。  

### データセットのスプリットをランダムにする

この時、これまでの実験がエポック数が大きすぎるため、学習率を1e-3から1e-2にあげ、エポック数を1000から300にした。ロスのログは`log_output_v4.csv`にある。

#### (1) 処理時間  
同様に処理時間を計算した。  

time: `11.440572738647461` sec

#### (2) PR曲線  

<p align="center"><img src="https://user-images.githubusercontent.com/77057905/178958094-bd5a1ae9-4afe-413a-8f32-e1a5e87c861b.png" width="45%">
<img src="https://user-images.githubusercontent.com/77057905/178958192-a94415e7-e632-4655-a3fa-d92da559eceb.png" width="45%"></p>
<p align="center">図3 データセットをランダムに分割して学習した時のPR曲線</p>
図3に示すようなPR曲線となり、average_precisionが0.6409863371552706となった。  
RGBに変換した時と比べて、PR曲線右肩下がりになり、更にaverage_precisionも上がった。従って、性能が向上した事がわかる。

## 考察
最初の学習結果が芳しくなかったのは、白黒画像をRGBに変換した事よりもデータセットの分割の仕方が大きく影響していた事がわかった。

## 結論
本実験では、研究室で用意されたx3というデータセット（白黒画像）とU-Netを用いて、"butu"の検出を学習し、推論にてPR曲線とagerage precisionと処理時間によって学習結果を評価した。その結果、白黒画像をグレースケールのままにし、データセットをランダムに分割して学習することで**AP=0.6409863371552706**、**処理時間：11.440572738647461 sec**という結果になった。

## 参考文献
1. 小川雄太郎,"作りながら学ぶ！Pytorchによる発展ディープラーニング",マイナビ出版,p130(2021)

## Author
西川 凜  
東北大学工学部電気情報物理工学科4年


