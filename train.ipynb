{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cv2\n",
    "from utils.data_augumentation import (\n",
    "    Compose,\n",
    "    Scale,\n",
    "    RandomRotation,\n",
    "    RandomMirror,\n",
    "    Resize,\n",
    "    Normalize_Tensor,\n",
    ")\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_num=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_file_with_json(rootpath):\n",
    "    \"\"\"\n",
    "    jsonファイルを参照してbutuと背景クラスのみが入っているファイルのみのファイル名をリスト化する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rootpath : str\n",
    "        データフォルダへのパス\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret : file_names\n",
    "        データへのパスを格納したリスト\n",
    "    \"\"\"\n",
    "    json_dir = osp.join(rootpath, \"json\")\n",
    "    json_tempate = osp.join(rootpath, \"json\")\n",
    "    # print(json_dir)\n",
    "    # print(osp.exists(json_dir))\n",
    "    json_files = os.listdir(json_dir)\n",
    "    filenames = []\n",
    "    for json_file in json_files:\n",
    "        path = osp.join(json_tempate, json_file)\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "        shapes = json_load[\"shapes\"]\n",
    "        for shape in shapes:\n",
    "            if shape[\"label\"] != \"butu\":\n",
    "                is_butu = False\n",
    "                break\n",
    "            is_butu = True\n",
    "        if is_butu:\n",
    "            filenames.append(json_file)\n",
    "    # print(len(filenames))\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def make_datapath_list(rootpath, filenames):\n",
    "    \"\"\"\n",
    "    学習、検証の画像データとアノテーションデータのファイルパスリストを作成する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rootpath : str\n",
    "        データフォルダへのパス\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret : train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        データへのパスを格納したリスト\n",
    "    \"\"\"\n",
    "    image_files = [\n",
    "        osp.join(rootpath, \"image\", \"%s.png\" % os.path.splitext(filename)[0])\n",
    "        for filename in filenames\n",
    "    ]\n",
    "    train_img_list = list()\n",
    "    train_anno_list = list()\n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "    test_img_list = list()\n",
    "    test_anno_list = list()\n",
    "    annotate_files = [\n",
    "        osp.join(\n",
    "            rootpath, \"SegmentationClassPNG\", \"%s.png\" % os.path.splitext(filename)[0]\n",
    "        )\n",
    "        for filename in filenames\n",
    "    ]\n",
    "    # print(len(image_files))\n",
    "    # print(image_files[0])\n",
    "    # print(len(annotate_files))\n",
    "    # print(annotate_files[0])\n",
    "    num_train = len(image_files) * 8 // 10\n",
    "    num_val = (len(image_files) - num_train) // 2\n",
    "    num_test = len(image_files) - num_train - num_val\n",
    "    # print(num_train, num_val, num_test)\n",
    "\n",
    "    index = 0\n",
    "    for image, anno in zip(image_files, annotate_files):\n",
    "        if index < num_train:\n",
    "            train_img_list.append(image)\n",
    "            train_anno_list.append(anno)\n",
    "        elif index < num_train + num_val:\n",
    "            val_img_list.append(image)\n",
    "            val_anno_list.append(anno)\n",
    "        else:\n",
    "            test_img_list.append(image)\n",
    "            test_anno_list.append(anno)\n",
    "        index += 1\n",
    "\n",
    "    return (\n",
    "        train_img_list,\n",
    "        train_anno_list,\n",
    "        val_img_list,\n",
    "        val_anno_list,\n",
    "        test_img_list,\n",
    "        test_anno_list,\n",
    "    )\n",
    "\n",
    "\n",
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    画像とアノテーションの前処理クラス。訓練時と検証時で異なる動作をする。\n",
    "    画像のサイズをinput_size x input_sizeにする。\n",
    "    訓練時はデータオーギュメンテーションする。\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    input_size : int\n",
    "        リサイズ先の画像の大きさ。\n",
    "    color_mean : (R, G, B)\n",
    "        各色チャネルの平均値。\n",
    "    color_std : (R, G, B)\n",
    "        各色チャネルの標準偏差。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, color_mean, color_std):\n",
    "        self.data_transform = {\n",
    "            \"train\": Compose(\n",
    "                [\n",
    "                    Scale(scale=[0.5, 1.5]),\n",
    "                    RandomRotation(angle=[-10, 10]),\n",
    "                    RandomMirror(),\n",
    "                    Resize(input_size),\n",
    "                    Normalize_Tensor(color_mean, color_std),\n",
    "                ]\n",
    "            ),\n",
    "            \"val\": Compose(\n",
    "                [\n",
    "                    Resize(input_size),\n",
    "                    Normalize_Tensor(color_mean, color_std),\n",
    "                ]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def __call__(self, phase, img, anno_class_img):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase : 'train' or 'val'\n",
    "            前処理のモードを指定。\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img, anno_class_img)\n",
    "\n",
    "\n",
    "class VOCDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    VOC2012のDatasetを作成するクラス。PyTorchのDatasetクラスを継承。\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    img_list : リスト\n",
    "        画像のパスを格納したリスト\n",
    "    anno_list : リスト\n",
    "        アノテーションへのパスを格納したリスト\n",
    "    phase : 'train' or 'test'\n",
    "        学習か訓練かを設定する。\n",
    "    transform : object\n",
    "        前処理クラスのインスタンス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_list, anno_list, phase, transform):\n",
    "        self.img_list = img_list\n",
    "        self.anno_list = anno_list\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"画像の枚数を返す\"\"\"\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        前処理をした画像のTensor形式のデータとアノテーションを取得\n",
    "        \"\"\"\n",
    "        img, anno_class_img = self.pull_item(index)\n",
    "        return img, anno_class_img\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        \"\"\"画像のTensor形式のデータ、アノテーションを取得する\"\"\"\n",
    "\n",
    "        image_file_path = self.img_list[index]\n",
    "        img = Image.open(image_file_path).convert(mode=\"RGB\")  # [高さ][幅][色RGB]\n",
    "        anno_file_path = self.anno_list[index]\n",
    "        anno_class_img = Image.open(anno_file_path)  # [高さ][幅]\n",
    "        img, anno_class_img = self.transform(self.phase, img, anno_class_img)\n",
    "\n",
    "        return img, anno_class_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloder(rootpath, batch_size=8):\n",
    "    filenames = select_file_with_json(rootpath)\n",
    "    (\n",
    "        train_img_list,\n",
    "        train_anno_list,\n",
    "        val_img_list,\n",
    "        val_anno_list,\n",
    "        _,\n",
    "        _,\n",
    "    ) = make_datapath_list(rootpath, filenames)\n",
    "\n",
    "    color_mean = (0.485, 0.456, 0.406)\n",
    "    color_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "    train_dataset = VOCDataset(\n",
    "        train_img_list,\n",
    "        train_anno_list,\n",
    "        phase=\"train\",\n",
    "        transform=DataTransform(\n",
    "            input_size=475, color_mean=color_mean, color_std=color_std\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    val_dataset = VOCDataset(\n",
    "        val_img_list,\n",
    "        val_anno_list,\n",
    "        phase=\"val\",\n",
    "        transform=DataTransform(\n",
    "            input_size=475, color_mean=color_mean, color_std=color_std\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    train_dataloader = data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "    return dataloaders_dict\n",
    "\n",
    "\n",
    "def lambda_epoch(epoch):\n",
    "    max_epoch = 1\n",
    "    return math.pow((1 - epoch / max_epoch), 0.9)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    net,\n",
    "    dataloaders_dict,\n",
    "    scheduler,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    cross_entropy_loss,\n",
    "    cuda_num=0,\n",
    "    batch_multiplier=3,\n",
    "):\n",
    "    device = torch.device(\n",
    "        \"cuda:\" + str(cuda_num) if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(\"使用デバイス：\", device)\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs = len(dataloaders_dict[\"val\"].dataset)\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "    # print(batch_size)\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        print(\"-------------\")\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        print(\"-------------\")\n",
    "\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                scheduler.step()  # 最適化schedulerの更新\n",
    "                optimizer.zero_grad()\n",
    "                print(\"（train）\")\n",
    "\n",
    "            else:\n",
    "                if (epoch + 1) % 5 == 0:\n",
    "                    net.eval()  # モデルを検証モードに\n",
    "                    print(\"-------------\")\n",
    "                    print(\"（val）\")\n",
    "                else:\n",
    "                    # 検証は5回に1回だけ行う\n",
    "                    continue\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            count = 0  # multiple minibatch\n",
    "            for imges, anno_class_imges in dataloaders_dict[phase]:\n",
    "                # print(imges.shape)\n",
    "                # print(anno_class_imges.shape)\n",
    "                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
    "                if imges.size()[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                imges = imges.to(device)\n",
    "                anno_class_imges = anno_class_imges.to(device)\n",
    "\n",
    "                # multiple minibatchでのパラメータの更新\n",
    "                if (phase == \"train\") and (count == 0):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count = batch_multiplier\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = net(imges)\n",
    "                    # print(outputs.shape)\n",
    "                    loss = (\n",
    "                        cross_entropy_loss(\n",
    "                            outputs,\n",
    "                            anno_class_imges.long(),\n",
    "                        )\n",
    "                        / batch_multiplier\n",
    "                    )\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()  # 勾配の計算\n",
    "                        count -= 1  # multiple minibatch\n",
    "\n",
    "                        if iteration % 10 == 0:  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print(\n",
    "                                \"イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.\".format(\n",
    "                                    iteration,\n",
    "                                    loss.item() / batch_size * batch_multiplier,\n",
    "                                    duration,\n",
    "                                )\n",
    "                            )\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item() * batch_multiplier\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item() * batch_multiplier\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print(\"-------------\")\n",
    "        print(\n",
    "            \"epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}\".format(\n",
    "                epoch + 1,\n",
    "                epoch_train_loss / num_train_imgs,\n",
    "                epoch_val_loss / num_val_imgs,\n",
    "            )\n",
    "        )\n",
    "        print(\"timer:  {:.4f} sec.\".format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # ログを保存\n",
    "        log_epoch = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": epoch_train_loss / num_train_imgs,\n",
    "            \"val_loss\": epoch_val_loss / num_val_imgs,\n",
    "        }\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "\n",
    "    # 最後のネットワークを保存する\n",
    "    torch.save(\n",
    "        net.state_dict(),\n",
    "        \"/localtmp/users/rin/Unet_\" + str(epoch + 1) + \".pth\",\n",
    "    )\n",
    "    shutil.move(\n",
    "        \"/localtmp/users/rin/Unet_\" + str(epoch + 1) + \".pth\",\n",
    "        \"./weights\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath = \"../data/x3\"\n",
    "dataloaders_dict=make_dataloder(rootpath=rootpath, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了：学習済みの重みをロードしました\n"
     ]
    }
   ],
   "source": [
    "net = UNet(n_channels=3, n_classes=2)\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-3,momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:1\n",
      "使用デバイス： cuda:1\n",
      "-------------\n",
      "Epoch 1/1\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 10 || Loss: 0.3840 || 10iter: 10.0148 sec.\n",
      "イテレーション 20 || Loss: 0.3795 || 10iter: 10.0047 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:0.3648 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  20.7827 sec.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda:\" + str(cuda_num) if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "print(\"使用デバイス：\", device)\n",
    "weights = torch.tensor([1.0, 100.0]).to(device)\n",
    "net.apply(weights_init)\n",
    "train_model(\n",
    "    net,\n",
    "    dataloaders_dict,\n",
    "    scheduler,\n",
    "    optimizer,\n",
    "    num_epochs=1,\n",
    "    cross_entropy_loss=nn.CrossEntropyLoss(weight=weights),\n",
    "    cuda_num=cuda_num,\n",
    "    batch_multiplier=6,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cuda_10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0020e4d3e84c147d6bc393b61144490ccd97102b6a86d3cc7eb3a890798c659"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
