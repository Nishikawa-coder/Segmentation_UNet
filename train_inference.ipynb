{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cv2\n",
    "from utils.data_augumentation import (\n",
    "    Compose,\n",
    "    Scale,\n",
    "    RandomRotation,\n",
    "    RandomMirror,\n",
    "    Resize,\n",
    "    Normalize_Tensor,\n",
    ")\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_file_with_json(rootpath):\n",
    "    \"\"\"\n",
    "    jsonファイルを参照してbutuと背景クラスのみが入っているファイルのみのファイル名をリスト化する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rootpath : str\n",
    "        データフォルダへのパス\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret : file_names\n",
    "        データへのパスを格納したリスト\n",
    "    \"\"\"\n",
    "    json_dir = osp.join(rootpath, \"json\")\n",
    "    json_tempate = osp.join(rootpath, \"json\")\n",
    "    # print(json_dir)\n",
    "    # print(osp.exists(json_dir))\n",
    "    json_files = os.listdir(json_dir)\n",
    "    filenames = []\n",
    "    for json_file in json_files:\n",
    "        path = osp.join(json_tempate, json_file)\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "        shapes = json_load[\"shapes\"]\n",
    "        for shape in shapes:\n",
    "            if shape[\"label\"] != \"butu\":\n",
    "                is_butu = False\n",
    "                break\n",
    "            is_butu = True\n",
    "        if is_butu:\n",
    "            filenames.append(json_file)\n",
    "    # print(len(filenames))\n",
    "    return filenames\n",
    "\n",
    "def make_random_datapath_list(rootpath, filenames):\n",
    "    \"\"\"\n",
    "    学習、検証の画像データとアノテーションデータのファイルパスリストをランダムに作成する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rootpath : str\n",
    "        データフォルダへのパス\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret : train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        データへのパスを格納したリスト\n",
    "    \"\"\"\n",
    "    img_path_list = [\n",
    "        osp.join(rootpath, \"image\", \"%s.png\" % os.path.splitext(filename)[0])\n",
    "        for filename in filenames\n",
    "    ]\n",
    "    anno_path_list = [\n",
    "        osp.join(\n",
    "            rootpath, \"SegmentationClassPNG\", \"%s.png\" % os.path.splitext(filename)[0]\n",
    "        )\n",
    "        for filename in filenames\n",
    "    ]\n",
    "    num_train = len(img_path_list) * 8 // 10\n",
    "    num_val = (len(img_path_list) - num_train) // 2\n",
    "    num_test = len(img_path_list) - num_train - num_val\n",
    "    (tmp_img, test_img_list, tmp_anno, test_anno_list) = train_test_split(\n",
    "        img_path_list,\n",
    "        anno_path_list,\n",
    "        train_size=num_train + num_val,\n",
    "        test_size=num_test,\n",
    "        shuffle=True,\n",
    "        random_state=1,\n",
    "    )\n",
    "\n",
    "    (train_img_list, val_img_list, train_anno_list, val_anno_list) = train_test_split(\n",
    "        tmp_img,\n",
    "        tmp_anno,\n",
    "        train_size=num_train,\n",
    "        test_size=num_val,\n",
    "        shuffle=True,\n",
    "        random_state=1,\n",
    "    )\n",
    "    return (\n",
    "        train_img_list,\n",
    "        train_anno_list,\n",
    "        val_img_list,\n",
    "        val_anno_list,\n",
    "        test_img_list,\n",
    "        test_anno_list,\n",
    "    )\n",
    "\n",
    "\n",
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    画像とアノテーションの前処理クラス。訓練時と検証時で異なる動作をする。\n",
    "    画像のサイズをinput_size x input_sizeにする。\n",
    "    訓練時はデータオーギュメンテーションする。\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    input_size : int\n",
    "        リサイズ先の画像の大きさ。\n",
    "    color_mean : (R, G, B)\n",
    "        各色チャネルの平均値。\n",
    "    color_std : (R, G, B)\n",
    "        各色チャネルの標準偏差。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, color_mean, color_std):\n",
    "        self.data_transform = {\n",
    "            \"train\": Compose(\n",
    "                [\n",
    "                    Scale(scale=[0.5, 1.5]),\n",
    "                    RandomRotation(angle=[-10, 10]),\n",
    "                    RandomMirror(),\n",
    "                    Resize(input_size),\n",
    "                    Normalize_Tensor(color_mean, color_std),\n",
    "                ]\n",
    "            ),\n",
    "            \"val\": Compose(\n",
    "                [\n",
    "                    Resize(input_size),\n",
    "                    Normalize_Tensor(color_mean, color_std),\n",
    "                ]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def __call__(self, phase, img, anno_class_img):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase : 'train' or 'val'\n",
    "            前処理のモードを指定。\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img, anno_class_img)\n",
    "\n",
    "\n",
    "class VOCDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    VOC2012のDatasetを作成するクラス。PyTorchのDatasetクラスを継承。\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    img_list : リスト\n",
    "        画像のパスを格納したリスト\n",
    "    anno_list : リスト\n",
    "        アノテーションへのパスを格納したリスト\n",
    "    phase : 'train' or 'val'\n",
    "        学習か訓練かを設定する。\n",
    "    transform : object\n",
    "        前処理クラスのインスタンス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_list, anno_list, phase, transform):\n",
    "        self.img_list = img_list\n",
    "        self.anno_list = anno_list\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"画像の枚数を返す\"\"\"\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        前処理をした画像のTensor形式のデータとアノテーションを取得\n",
    "        \"\"\"\n",
    "        img, anno_class_img = self.pull_item(index)\n",
    "        return img, anno_class_img\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        \"\"\"画像のTensor形式のデータ、アノテーションを取得する\"\"\"\n",
    "\n",
    "        image_file_path = self.img_list[index]\n",
    "        img = Image.open(image_file_path)  # [高さ][幅]\n",
    "        anno_file_path = self.anno_list[index]\n",
    "        anno_class_img = Image.open(anno_file_path)  # [高さ][幅]\n",
    "        img, anno_class_img = self.transform(self.phase, img, anno_class_img)\n",
    "\n",
    "        return img, anno_class_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloder(rootpath, batch_size=8):\n",
    "    filenames = select_file_with_json(rootpath)\n",
    "    (\n",
    "        train_img_list,\n",
    "        train_anno_list,\n",
    "        val_img_list,\n",
    "        val_anno_list,\n",
    "        _,\n",
    "        _,\n",
    "    ) = make_random_datapath_list(rootpath, filenames)\n",
    "\n",
    "    color_mean = 0.18228737997050898\n",
    "    color_std = 0.15940997135888293\n",
    "\n",
    "    train_dataset = VOCDataset(\n",
    "        train_img_list,\n",
    "        train_anno_list,\n",
    "        phase=\"train\",\n",
    "        transform=DataTransform(\n",
    "            input_size=475, color_mean=color_mean, color_std=color_std\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    val_dataset = VOCDataset(\n",
    "        val_img_list,\n",
    "        val_anno_list,\n",
    "        phase=\"val\",\n",
    "        transform=DataTransform(\n",
    "            input_size=475, color_mean=color_mean, color_std=color_std\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    train_dataloader = data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "    return dataloaders_dict\n",
    "\n",
    "\n",
    "def lambda_epoch(epoch):\n",
    "    max_epoch = 1\n",
    "    return math.pow((1 - epoch / max_epoch), 0.9)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    net,\n",
    "    dataloaders_dict,\n",
    "    scheduler,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    cross_entropy_loss,\n",
    "    cuda_num=0,\n",
    "    batch_multiplier=3,\n",
    "):\n",
    "    device = torch.device(\n",
    "        \"cuda:\" + str(cuda_num) if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(\"使用デバイス：\", device)\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs = len(dataloaders_dict[\"val\"].dataset)\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "    # print(batch_size)\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        print(\"-------------\")\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        print(\"-------------\")\n",
    "\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                scheduler.step()  # 最適化schedulerの更新\n",
    "                optimizer.zero_grad()\n",
    "                print(\"（train）\")\n",
    "\n",
    "            else:\n",
    "                if (epoch + 1) % 5 == 0:\n",
    "                    net.eval()  # モデルを検証モードに\n",
    "                    print(\"-------------\")\n",
    "                    print(\"（val）\")\n",
    "                else:\n",
    "                    # 検証は5回に1回だけ行う\n",
    "                    continue\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            count = 0  # multiple minibatch\n",
    "            for imges, anno_class_imges in dataloaders_dict[phase]:\n",
    "                # print(imges.shape)\n",
    "                # print(anno_class_imges.shape)\n",
    "                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
    "                if imges.size()[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                imges = imges.to(device)\n",
    "                anno_class_imges = anno_class_imges.to(device)\n",
    "\n",
    "                # multiple minibatchでのパラメータの更新\n",
    "                if (phase == \"train\") and (count == 0):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count = batch_multiplier\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = net(imges)\n",
    "                    # print(outputs.shape)\n",
    "                    loss = (\n",
    "                        cross_entropy_loss(\n",
    "                            outputs,\n",
    "                            anno_class_imges.long(),\n",
    "                        )\n",
    "                        / batch_multiplier\n",
    "                    )\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()  # 勾配の計算\n",
    "                        count -= 1  # multiple minibatch\n",
    "\n",
    "                        if iteration % 10 == 0:  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print(\n",
    "                                \"イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.\".format(\n",
    "                                    iteration,\n",
    "                                    loss.item() / batch_size * batch_multiplier,\n",
    "                                    duration,\n",
    "                                )\n",
    "                            )\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item() * batch_multiplier\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item() * batch_multiplier\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print(\"-------------\")\n",
    "        print(\n",
    "            \"epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}\".format(\n",
    "                epoch + 1,\n",
    "                epoch_train_loss / num_train_imgs,\n",
    "                epoch_val_loss / num_val_imgs,\n",
    "            )\n",
    "        )\n",
    "        print(\"timer:  {:.4f} sec.\".format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # ログを保存\n",
    "        log_epoch = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": epoch_train_loss / num_train_imgs,\n",
    "            \"val_loss\": epoch_val_loss / num_val_imgs,\n",
    "        }\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "\n",
    "    # 最後のネットワークを保存する\n",
    "    torch.save(\n",
    "        net.state_dict(),\n",
    "        \"/localtmp/users/rin/Unet_\" + str(epoch + 1) + \".pth\",\n",
    "    )\n",
    "    shutil.move(\n",
    "        \"/localtmp/users/rin/Unet_\" + str(epoch + 1) + \".pth\",\n",
    "        \"./weights\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath = \"../data/x3\"\n",
    "dataloaders_dict=make_dataloder(rootpath=rootpath, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了：学習済みの重みをロードしました\n"
     ]
    }
   ],
   "source": [
    "net = UNet(n_channels=1, n_classes=2)\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-2,momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n",
      "使用デバイス： cuda:0\n",
      "-------------\n",
      "Epoch 1/1\n",
      "-------------\n",
      "（train）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usrs/rin/miniconda3/envs/cuda_10.1/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "イテレーション 10 || Loss: 0.1686 || 10iter: 16.3255 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:0.1735 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  23.2537 sec.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda:\" + str(cuda_num) if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "print(\"使用デバイス：\", device)\n",
    "weights = torch.tensor([1.0, 100.0]).to(device)\n",
    "net.apply(weights_init)\n",
    "# train_model(\n",
    "#     net,\n",
    "#     dataloaders_dict,\n",
    "#     scheduler,\n",
    "#     optimizer,\n",
    "#     num_epochs=1,\n",
    "#     cross_entropy_loss=nn.CrossEntropyLoss(weight=weights),\n",
    "#     cuda_num=cuda_num,\n",
    "#     batch_multiplier=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "！ここから推論コード！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス: cuda:0\n",
      "ネットワーク設定完了：学習済みの重みをロードしました\n"
     ]
    }
   ],
   "source": [
    "net = UNet(n_channels=1, n_classes=2)\n",
    "state_dict = torch.load(\"./weights/Unet_v4300.pth\",map_location={'cuda:'+str(cuda_num): 'cpu'})\n",
    "print(\"使用デバイス: cuda:\"+str(cuda_num))\n",
    "net.load_state_dict(state_dict)\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = select_file_with_json(rootpath)\n",
    "(\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    "    test_img_list,\n",
    "    test_anno_list,\n",
    ") = make_random_datapath_list(rootpath, filenames)\n",
    "color_mean = 0.18228737997050898\n",
    "color_std = 0.15940997135888293\n",
    "test_dataset = VOCDataset(test_img_list, test_anno_list, phase=\"val\", transform=DataTransform(\n",
    "input_size=475, color_mean=color_mean, color_std=color_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detection(test_img_list,test_anno_list,test_dataset):\n",
    "    \"\"\"\n",
    "    推論結果を表示する関数（緑:tp,赤:fp,青:fn）\n",
    "    \n",
    "    input:\n",
    "        test_img_list\n",
    "        test_anno_list\n",
    "        test_dataset\n",
    "    \"\"\"\n",
    "    time_all=0\n",
    "    for index in range(len(test_img_list)):\n",
    "        image_file_path = test_img_list[index]\n",
    "        img_original = Image.open(image_file_path).convert(mode=\"RGB\")   # [高さ][幅][色RGB]\n",
    "        img_width, img_height = img_original.size\n",
    "        anno_file_path = test_anno_list[index]\n",
    "        anno_class_img = Image.open(anno_file_path)   # [高さ][幅][色RGB]\n",
    "        gt =Image.open(anno_file_path).convert('RGBA')\n",
    "        p_palette = anno_class_img.getpalette()\n",
    "        net.eval()\n",
    "        img, anno_class_img = test_dataset.__getitem__(index)\n",
    "        x = img.unsqueeze(0)  # ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
    "        start = time.time()\n",
    "        outputs = net(x)\n",
    "        t = time.time() - start\n",
    "        time_all+=t\n",
    "        y = outputs\n",
    "        y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
    "        y = np.argmax(y, axis=0)\n",
    "        anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "        anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
    "        anno_class_img.putpalette(p_palette)\n",
    "        anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "        trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "        for x in range(img_width):\n",
    "            for y in range(img_height):\n",
    "                pixel = anno_class_img.getpixel((x, y))\n",
    "                pixel_gt = gt.getpixel((x, y))\n",
    "                if (pixel[0] != 0 or pixel[1] != 0 or pixel[2] != 0)and(pixel_gt[0] != 0 or pixel_gt[1] != 0 or pixel_gt[2] != 0):\n",
    "                    trans_img.putpixel((x, y), (0, 255,0, 200))\n",
    "                elif pixel[0] != 0 or pixel[1] != 0 or pixel[2] != 0 :\n",
    "                    trans_img.putpixel((x, y), (120, 0,0, 200))\n",
    "                elif pixel_gt[0] != 0 or pixel_gt[1] != 0 or pixel_gt[2] != 0:\n",
    "                    trans_img.putpixel((x, y), (0, 0, 255, 200))\n",
    "        result = Image.alpha_composite(img_original.convert('RGBA'), trans_img)\n",
    "        plt.imshow(result)\n",
    "        plt.show()\n",
    "    print(time_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "緑：正しい推論、赤:間違った推論、青:推論されなかった gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_detection(test_img_list,test_anno_list,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_true_pred(net,test_anno_list,test_dataset):\n",
    "    \"\"\"\n",
    "    y_trueとy_predを出力する関数\n",
    "\n",
    "    input: \n",
    "        anno_img:PIL.Image.Image image mode=RGB の推論データ情報のリスト\n",
    "        anno_img_gt:PIL.Image.Image image mode=RGB のgtデータ情報のリスト\n",
    "    return:\n",
    "        y_true_list\n",
    "        y_pred_list\n",
    "    \"\"\"\n",
    "    y_true_list=[]\n",
    "    y_pred_list=[]\n",
    "    softmax=nn.Softmax(dim=1)\n",
    "    for index,gt_path in enumerate(test_anno_list):\n",
    "        gt = Image.open(gt_path)   # [高さ][幅]\n",
    "        # p_palette = gt.getpalette()\n",
    "        img_width, img_height = gt.size\n",
    "        y_true=np.array(gt).flatten()\n",
    "        y_true_list=np.hstack((y_true_list, y_true))\n",
    "        img_475, _ = test_dataset.__getitem__(index)\n",
    "        net.eval()\n",
    "        x = img_475.unsqueeze(0)\n",
    "        outputs = net(x)\n",
    "        y = softmax(outputs)\n",
    "        y = y[0].detach().numpy()\n",
    "        y=y[1]\n",
    "        detection = Image.fromarray(np.float32(y))\n",
    "        detection = detection.resize((img_width, img_height), Image.NEAREST)\n",
    "        # detection.putpalette(p_palette)\n",
    "        y_pred=np.array(detection).flatten()\n",
    "        y_pred_list=np.hstack((y_pred_list,y_pred))\n",
    "\n",
    "    return y_true_list,y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_list,y_pred_list=generate_true_pred(net,test_anno_list,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0068322  0.00682941 0.00682946 ... 1.         1.         1.        ]\n",
      "[1.00000000e+00 9.99584437e-01 9.99584437e-01 ... 1.45446990e-03\n",
      " 4.15562828e-04 0.00000000e+00]\n",
      "[0.00255525 0.00255525 0.00255529 ... 0.99998832 0.99998891 0.99999177]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.6403756480680405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "precision, recall, thresholds = precision_recall_curve(y_true_list, y_pred_list)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(thresholds)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(-0.05, 1.1)\n",
    "ax.set_ylim(-0.05, 1.1)\n",
    "ax.grid()\n",
    "ax.set_title(\"PR curve\")\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Presicion\")\n",
    "ax.plot(recall, precision, \"bo-\", label=\"precision\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# my_auc=(-1)*(np.diff(recall) * precision[1:]).sum()\n",
    "# print(\"auc: \"+str(my_auc))\n",
    "print(\"auc: \"+str(auc(recall,precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usrs/rin/miniconda3/envs/cuda_10.1/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo-\" (-> color='b'). The keyword argument will take precedence.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_precision: 0.6409863371552706\n"
     ]
    }
   ],
   "source": [
    "modified_recall = np.concatenate([[1], recall, [0]])\n",
    "modified_precision = np.concatenate([[0], precision, [0]])\n",
    "modified_precision2 = np.maximum.accumulate(modified_precision)\n",
    "average_precision = (-1)*(np.diff(modified_recall) * modified_precision2[1:]).sum()\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(-0.05, 1.1)\n",
    "ax.set_ylim(-0.05, 1.1)\n",
    "ax.grid()\n",
    "ax.set_title(\"PR curve after interpolated\")\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Presicion\")\n",
    "ax.plot(modified_recall, modified_precision2, \"bo-\", label=\"average_precision\",color='red')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "print(\"average_precision: \"+str(auc(modified_recall, modified_precision2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cuda_10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0020e4d3e84c147d6bc393b61144490ccd97102b6a86d3cc7eb3a890798c659"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
